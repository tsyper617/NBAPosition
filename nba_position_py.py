# -*- coding: utf-8 -*-
"""NBA Position.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bG-Dfp1eWotu-8CLX7I5lJcdEchkb5cw
"""

from bs4 import BeautifulSoup
import requests

global positions
positions = {1: None, 2: None, 3: None, 4: None, 5: None}

# Example URL to scrape
url = 'https://www.cbssports.com/nba/teams/BOS/boston-celtics/stats/regular/'

# Send a GET request to the URL
response = requests.get(url)

# Check if the request was successful (status code 200)
if response.status_code == 200:
    # Parse the HTML content using Beautiful Soup
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find elements using Beautiful Soup's methods (e.g., find(), find_all())
    # Example: Find all <a> tags (hyperlinks) in the parsed content
    rows = soup.find_all('tr', class_='TableBase-bodyTr')

# Iterate through each row and print its content
for row in rows:
    # Extract all 'td' elements within the row
    cells = row.find_all('td')

    # Extract text content from each 'td' element and print
    row_content = [cell.get_text(strip=True) for cell in cells]
   # print(row_content)

else:
  print("Cannot retrieve web page")

import csv
import pandas as pd

# Provided table data as a string
table_data = '''Rk,Player,Age,G,GS,MP,FG,FGA,FG%,3P,3PA,3P%,2P,2PA,2P%,eFG%,FT,FTA,FT%,ORB,DRB,TRB,AST,STL,BLK,TOV,PF,PTS
1,Jayson Tatum,25,31,31,36.8,9.3,19.6,.474,3.0,8.5,.347,6.3,11.1,.571,.549,5.5,6.8,.806,1.0,7.5,8.5,4.5,1.0,0.5,2.9,2.1,27.0
2,Jrue Holiday,33,30,30,34.5,4.9,10.8,.454,1.9,4.5,.419,3.0,6.3,.479,.542,1.2,1.5,.804,1.6,4.9,6.5,4.8,0.9,0.8,2.0,1.7,12.9
3,Jaylen Brown,27,31,31,33.9,8.7,18.2,.480,2.2,6.3,.344,6.6,11.9,.553,.540,3.1,4.1,.742,1.0,4.2,5.1,3.6,1.1,0.6,2.6,2.8,22.7
4,Derrick White,29,30,30,32.4,5.7,11.6,.494,2.8,6.6,.422,2.9,5.0,.591,.615,2.8,3.1,.892,0.7,3.2,3.9,5.3,1.2,1.3,1.7,2.1,17.0
5,Kristaps Porziņģis,28,24,24,30.8,7.0,13.1,.535,1.8,5.3,.331,5.3,7.8,.674,.602,4.8,5.8,.835,1.7,5.7,7.3,1.7,0.8,1.8,1.6,3.0,20.6
6,Al Horford,37,28,12,26.4,2.9,5.9,.482,1.4,3.8,.377,1.4,2.1,.667,.602,0.4,0.4,1.000,1.5,5.4,6.9,2.9,0.5,1.1,0.8,1.6,7.5
7,Sam Hauser,26,33,4,22.3,2.9,6.5,.453,2.4,5.6,.422,0.6,0.9,.655,.636,0.2,0.3,.800,0.8,2.7,3.5,1.0,0.5,0.3,0.5,1.5,8.5
8,Payton Pritchard,26,33,0,20.6,2.7,6.5,.413,1.6,4.3,.378,1.0,2.1,.486,.540,0.4,0.6,.650,1.0,2.2,3.2,3.1,0.4,0.1,0.5,1.2,7.4
9,Neemias Queta,24,12,0,14.5,2.2,3.8,.578,0.0,0.0,,2.2,3.8,.578,.578,1.0,1.3,.750,2.3,3.0,5.3,0.6,0.5,0.3,0.4,2.2,5.3
10,Luke Kornet,28,20,1,14.2,2.3,3.2,.730,0.0,0.0,,2.3,3.2,.730,.730,0.7,0.8,.875,1.8,1.8,3.5,0.8,0.5,1.0,0.4,1.2,5.3
11,Oshae Brissett,25,17,0,11.2,1.1,2.2,.474,0.4,0.9,.375,0.7,1.3,.545,.553,0.6,1.0,.588,1.1,1.6,2.7,0.5,0.4,0.0,0.3,0.9'''

# Splitting table data into rows
rows = table_data.split('\n')

# Write data to a CSV file
with open('data.csv', 'w', newline='') as csvfile:
    csv_writer = csv.writer(csvfile)

    # Write header
    csv_writer.writerow(rows[0].split(','))

    # Write each row
    for row in rows[1:]:
        csv_writer.writerow(row.split(','))

# Read the CSV file into a pandas DataFrame
df = pd.read_csv('data.csv')

# Display the DataFrame
#print(df)

#print only the points and the name of the player of the top 5
top_5_players = df.nlargest(5, 'PTS')[['Player', 'PTS']]

# Display the top 5 players and their points
print(top_5_players)

import requests
from bs4 import BeautifulSoup

# The URL of the website you want to scrape
url = 'https://www.basketball-reference.com/players/t/tatumja01/gamelog/2024'  # Replace this with the URL of the website you want to scrape

  # Replace with the URL of the website you want to scrape
response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all <td> tags with attribute data-stat="pts"
    td_tags = soup.find_all('td', {'data-stat': 'pts'})

    # Extract points and put them into an array of numbers
    points = [int(td.text.strip()) for td in td_tags]

    # Calculate the percentage of times points fall below 27.9
    below_threshold = sum(point < 27.0 for point in points)
    total_points = len(points)
    percentage_below_threshold = (below_threshold / total_points) * 100

    positions[1] = percentage_below_threshold

    print(f"Percentage of times Tatum points fall below 27.0: {percentage_below_threshold:.2f}%") # Extract and print the text content of the <td> tag
else:
    print('Failed to retrieve the web page')

import requests
from bs4 import BeautifulSoup

# The URL of the website you want to scrape
url = 'https://www.basketball-reference.com/players/b/brownja02/gamelog/2024'  # Replace this with the URL of the website you want to scrape

  # Replace with the URL of the website you want to scrape
response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all <td> tags with attribute data-stat="pts"
    td_tags = soup.find_all('td', {'data-stat': 'pts'})

    # Extract points and put them into an array of numbers
    points = [int(td.text.strip()) for td in td_tags]

    # Calculate the percentage of times points fall below 27.9
    below_threshold = sum(point < 22.7 for point in points)
    total_points = len(points)
    percentage_below_threshold = (below_threshold / total_points) * 100

    positions[2] = percentage_below_threshold

    print(f"Percentage of times Brown points fall below 22.7: {percentage_below_threshold:.2f}%") # Extract and print the text content of the <td> tag
else:
    print('Failed to retrieve the web page')

import requests
from bs4 import BeautifulSoup

# The URL of the website you want to scrape
url = 'https://www.basketball-reference.com/players/p/porzikr01/gamelog/2024'  # Replace this with the URL of the website you want to scrape

  # Replace with the URL of the website you want to scrape
response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all <td> tags with attribute data-stat="pts"
    td_tags = soup.find_all('td', {'data-stat': 'pts'})

    # Extract points and put them into an array of numbers
    points = [int(td.text.strip()) for td in td_tags]

    # Calculate the percentage of times points fall below 27.9
    below_threshold = sum(point < 20.6 for point in points)
    total_points = len(points)
    percentage_below_threshold = (below_threshold / total_points) * 100

    positions[3] = percentage_below_threshold


    print(f"Percentage of times Porzingis points fall below 20.6: {percentage_below_threshold:.2f}%") # Extract and print the text content of the <td> tag
else:
    print('Failed to retrieve the web page')

import requests
from bs4 import BeautifulSoup

# The URL of the website you want to scrape
url = 'https://www.basketball-reference.com/players/w/whitede01/gamelog/2024'  # Replace this with the URL of the website you want to scrape

  # Replace with the URL of the website you want to scrape
response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all <td> tags with attribute data-stat="pts"
    td_tags = soup.find_all('td', {'data-stat': 'pts'})

    # Extract points and put them into an array of numbers
    points = [int(td.text.strip()) for td in td_tags]

    # Calculate the percentage of times points fall below 27.9
    below_threshold = sum(point < 17.0 for point in points)
    total_points = len(points)
    percentage_below_threshold = (below_threshold / total_points) * 100

    positions[4] = percentage_below_threshold


    print(f"Percentage of times White points fall below 17.0: {percentage_below_threshold:.2f}%") # Extract and print the text content of the <td> tag
else:
    print('Failed to retrieve the web page')

import requests
from bs4 import BeautifulSoup

# The URL of the website you want to scrape
url = 'https://www.basketball-reference.com/players/h/holidjr01/gamelog/2024'  # Replace this with the URL of the website you want to scrape

  # Replace with the URL of the website you want to scrape
response = requests.get(url)

if response.status_code == 200:
    soup = BeautifulSoup(response.content, 'html.parser')

    # Find all <td> tags with attribute data-stat="pts"
    td_tags = soup.find_all('td', {'data-stat': 'pts'})

    # Extract points and put them into an array of numbers
    points = [int(td.text.strip()) for td in td_tags]

    # Calculate the percentage of times points fall below 27.9
    below_threshold = sum(point < 12.9 for point in points)
    total_points = len(points)
    percentage_below_threshold = (below_threshold / total_points) * 100

    positions[5] = percentage_below_threshold


    print(f"Percentage of times Holiday points fall below 12.9: {percentage_below_threshold:.2f}%") # Extract and print the text content of the <td> tag
else:
    print('Failed to retrieve the web page')

import numpy as np

# Given data
positions = np.array([1, 2, 3, 4, 5])
percentages = np.array([48.38709677419355, 45.16129032258064, 45.83333333333333, 43.333333333333336, 43.333333333333336])

# Calculate the correlation coefficient
correlation_coefficient = np.corrcoef(positions, percentages)[0, 1]

print(f"Correlation coefficient between positions and percentages: {correlation_coefficient:.2f}")

#Here iwth a correlation of -0.9 as the position goes down, so does the likelihood that they will perform under the threshold.